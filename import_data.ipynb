{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary tools and set seed\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://dog-vs-cat-arnaud-test/dog-vs-cat...\n",
      "| [1 files][543.2 MiB/543.2 MiB]                                                \n",
      "Operation completed over 1 objects/543.2 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Copy train.zip file from GCP bucket\n",
    "\n",
    "! gsutil cp gs://dog-vs-cat-arnaud-test/dog-vs-cat /tmp/train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_zip = '/tmp/train.zip' # local path of downloaded .zip file\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/train-unzip') # contents are extracted to '/tmp' folder\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('/tmp/train-unzip/train/*') # creating a glob with all the pictures\n",
    "\n",
    "cat_files = [fn for fn in files if 'cat' in fn] # list with all the cat pictures thanks to the files names\n",
    "dog_files = [fn for fn in files if 'dog' in fn] # list of all the dog pictures thanks to the files names\n",
    "len(cat_files), len(dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat datasets: (1500,) (500,) (500,)\n",
      "Dog datasets: (1500,) (500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "cat_train = np.random.choice(cat_files, size=1500, replace=False) #Selecting 1500 random cat images for train\n",
    "dog_train = np.random.choice(dog_files, size=1500, replace=False) #Selecting 1500 random dog images for train\n",
    "cat_files = list(set(cat_files) - set(cat_train)) #removing the selected images from the pool of files\n",
    "dog_files = list(set(dog_files) - set(dog_train))\n",
    "\n",
    "cat_val = np.random.choice(cat_files, size=500, replace=False) #Selecting 500 random cat images for val\n",
    "dog_val = np.random.choice(dog_files, size=500, replace=False) #Selecting 500 random dog images for val\n",
    "cat_files = list(set(cat_files) - set(cat_val)) #removing the selected images from the pool of files\n",
    "dog_files = list(set(dog_files) - set(dog_val))\n",
    "\n",
    "cat_test = np.random.choice(cat_files, size=500, replace=False) #Selecting 500 random cat images for test\n",
    "dog_test = np.random.choice(dog_files, size=500, replace=False) #Selecting 500 random dog images for test\n",
    "\n",
    "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape)\n",
    "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining cat and dog images for train, val and test files\n",
    "\n",
    "train_files = np.concatenate([cat_train, dog_train])\n",
    "validate_files = np.concatenate([cat_val, dog_val])\n",
    "test_files = np.concatenate([cat_test, dog_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving training, validation and test data files to notebook directory\n",
    "\n",
    "train_dir = 'training_data'\n",
    "val_dir = 'validation_data'\n",
    "test_dir = 'test_data'\n",
    "\n",
    "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\n",
    "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None\n",
    "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None\n",
    "\n",
    "for fn in train_files:\n",
    "    shutil.copy(fn, train_dir)\n",
    "\n",
    "for fn in validate_files:\n",
    "    shutil.copy(fn, val_dir)\n",
    "    \n",
    "for fn in test_files:\n",
    "    shutil.copy(fn, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
