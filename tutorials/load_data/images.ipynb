{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mt9dL5dIir8X"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "ufPx7EiCiqgR"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ucMoYase6URl"
   },
   "source": [
    "# Load images with tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Wwu5SXZmEkB"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/images\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oxw4WahM7DU9"
   },
   "source": [
    "This tutorial provides a simple example of how to load an image dataset using `tf.data`.\n",
    "\n",
    "The dataset used in this example is distributed as directories of images, with one class of image per directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "hoQQiZDB6URn"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGXxBuPyKJw1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "  Downloading https://files.pythonhosted.org/packages/33/c3/0f209be711d6cf8a3a5fd30ac9347f4884a40cbbbe73d84d036ab3d29944/tf_nightly-1.15.0.dev20190730-cp27-cp27mu-manylinux1_x86_64.whl (102.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 102.2MB 11kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2.0,>=1.16.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 73kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/c3/65db90ec27181edf491c26aa998ae631e50cd1f04ee8d8d513a95e3937f3/grpcio-1.23.0-cp27-cp27mu-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 599kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting backports.weakref>=1.0rc1; python_version < \"3.4\" (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 10.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tf-estimator-nightly (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/2a/5a/b3dcfc02ae5f09a597cea0cc33e3d0d4ccbcf828a8598ec9683938b49e7d/tf_estimator_nightly-1.14.0.dev2019091101-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 2.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/95/d41cd87d147742ef72d5d1dc317318486e3fbffdadf24a60e70dedf01d56/google_pasta-0.1.7-py2-none-any.whl (55kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 9.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-applications>=1.0.8 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 4.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting wheel (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting functools32>=3.2.3 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/60/6ac26ad05857c601308d8fb9e87fa36d0ebf889423f47c3502ef034365db/functools32-3.2.3-2.tar.gz\n",
      "Collecting tb-nightly<1.16.0a0,>=1.15.0a0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/61/fab9bb94f10526d3e79057f3f0d8d4b7c2b7b39d10e7d71faa23f9b2b276/tb_nightly-1.15.0a20190911-py2-none-any.whl (3.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.8MB 349kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/4d/17/a92e707853e2fb48aea76dcdc200ea9a2f7d1ce6d1eff07ddfcf326184cb/gast-0.3.1.tar.gz\n",
      "Collecting keras-preprocessing>=1.0.5 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 11.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/60/19c2c3b563c8a5ebbc5f17982fd794f415cfc4633a8248ab3e23a47662bc/protobuf-3.9.1-cp27-cp27mu-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 984kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting enum34>=1.1.6; python_version < \"3.4\" (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/0d/7cbf64cac3f93617a2b6b079c0182e4a83a3e7a8964d3b0cc3d9758ba002/absl-py-0.8.0.tar.gz (102kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock>=2.0.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\" (from grpcio>=1.8.6->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.8->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 465kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/61/c0a1adf9ad80db012ed7191af98fa05faa95fa09eceb71bb6fa8b66e6a43/Werkzeug-0.15.6-py2.py3-none-any.whl (328kB)\n",
      "\u001b[K    100% |████████████████████████████████| 337kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/86/095d2f7829badc207c893dd4ac767e871f6cd547145df797ea26baea4e2e/setuptools-41.2.0-py2.py3-none-any.whl (576kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 11.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: opt-einsum, termcolor, keras-applications, functools32, gast, wrapt, absl-py\n",
      "  Running setup.py bdist_wheel for opt-einsum ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "  Running setup.py bdist_wheel for functools32 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/b5/18/32/77a1030457155606ba5e3ec3a8a57132b1a04b1c4f765177b2\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/d0/e8/de/cf6666d48241d10e5d7cd53fb3b5e447ea8e659f767d669b11\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/9a/1e/7a/456008eb5e47fd5de792c6139df6d5b3d5f71d51c6a0b94799\n",
      "Successfully built opt-einsum termcolor keras-applications functools32 gast wrapt absl-py\n",
      "Installing collected packages: numpy, futures, six, enum34, grpcio, backports.weakref, opt-einsum, tf-estimator-nightly, google-pasta, termcolor, h5py, keras-applications, astor, wheel, functools32, setuptools, protobuf, absl-py, werkzeug, markdown, tb-nightly, gast, keras-preprocessing, wrapt, funcsigs, mock, tf-nightly\n",
      "Successfully installed absl-py-0.8.0 astor-0.8.0 backports.weakref-1.0.post1 enum34-1.1.6 funcsigs-1.0.2 functools32-3.2.3.post2 futures-3.3.0 gast-0.3.1 google-pasta-0.1.7 grpcio-1.23.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 mock-3.0.5 numpy-1.16.5 opt-einsum-2.3.2 protobuf-3.9.1 setuptools-41.2.0 six-1.12.0 tb-nightly-1.15.0a20190911 termcolor-1.1.0 tf-estimator-nightly-1.14.0.dev2019091101 tf-nightly-1.15.0.dev20190730 werkzeug-0.15.6 wheel-0.33.6 wrapt-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHz3JONNEHlj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KT6CcaqgQewg"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxndJHNC8YPM"
   },
   "source": [
    "## Download and inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "wO0InzL66URu"
   },
   "source": [
    "### Retrieve the images\n",
    "\n",
    "Before you start any training, you'll need a set of images to teach the network about the new classes you want to recognize. We've created an archive of creative-commons licensed flower photos to use initially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN-Pc6Zd6awg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 1s 0us/step\n",
      "/home/jupyter/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "data_root = tf.keras.utils.get_file('flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)\n",
    "data_root = pathlib.Path(data_root)\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.keras/datasets/test-data\n"
     ]
    }
   ],
   "source": [
    "data_root_test = tf.keras.utils.get_file('test-data','gs://dog-vs-cat-arnaud-test/test-data', untar=True)\n",
    "data_root_test = pathlib.Path(data_root_test)\n",
    "print(data_root_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFkFK74oO--g"
   },
   "source": [
    "After downloading 218MB, you should now have a copy of the flower photos available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7onR_lWE7Njj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.keras/datasets/flower_photos/dandelion\n",
      "/home/jupyter/.keras/datasets/flower_photos/daisy\n",
      "/home/jupyter/.keras/datasets/flower_photos/roses\n",
      "/home/jupyter/.keras/datasets/flower_photos/LICENSE.txt\n",
      "/home/jupyter/.keras/datasets/flower_photos/sunflowers\n",
      "/home/jupyter/.keras/datasets/flower_photos/tulips\n"
     ]
    }
   ],
   "source": [
    "for item in data_root.iterdir():\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/.keras/datasets/test-data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7c229ef9fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_root_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/.keras/datasets/test-data'"
     ]
    }
   ],
   "source": [
    "for item in data_root_test.iterdir():\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yYX3ZRqGOuq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3670"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_BbYnLjbltQ"
   },
   "outputs": [],
   "source": [
    "all_image_paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkM-IpB-6URx"
   },
   "source": [
    "### Inspect the images\n",
    "Now let's have a quick look at a couple of the images, so we know what we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNGateQJ6UR1"
   },
   "outputs": [],
   "source": [
    "attributions = (data_root/\"LICENSE.txt\").read_text(encoding=\"utf8\").splitlines()[4:]\n",
    "attributions = [line.split(' CC-BY') for line in attributions]\n",
    "attributions = dict(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgowG2xu88Io"
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "def caption_image(image_path):\n",
    "    image_rel = pathlib.Path(image_path).relative_to(data_root)\n",
    "    return \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIjLi-nX0txI"
   },
   "outputs": [],
   "source": [
    "for n in range(3):\n",
    "  image_path = random.choice(all_image_paths)\n",
    "  display.display(display.Image(image_path))\n",
    "  print(caption_image(image_path))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaNOr-co3WKk"
   },
   "source": [
    "### Determine the label for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-weOQpDw2Jnu"
   },
   "source": [
    "List the available labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssUZ7Qh96UR3"
   },
   "outputs": [],
   "source": [
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9l_JEBql2OzS"
   },
   "source": [
    "Assign an index to each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8pCV46CzPlp"
   },
   "outputs": [],
   "source": [
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkXsHg162T9F"
   },
   "source": [
    "Create a list of every file, and its label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q62i1RBP4Q02"
   },
   "outputs": [],
   "source": [
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5L09icm9iph"
   },
   "source": [
    "### Load and format the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbqqRUS79ooq"
   },
   "source": [
    "TensorFlow includes all the tools you need to load and process images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQZdySHvksOu"
   },
   "outputs": [],
   "source": [
    "img_path = all_image_paths[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2t2h2XCcmK1Y"
   },
   "source": [
    "here is the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJfkyC_Qkt7A"
   },
   "outputs": [],
   "source": [
    "img_raw = tf.read_file(img_path)\n",
    "print(repr(img_raw)[:100]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opN8AVc8mSbz"
   },
   "source": [
    "Decode it into an image tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tm0tdrlfk0Bb"
   },
   "outputs": [],
   "source": [
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3k-Of2Tfmbeq"
   },
   "source": [
    "Resize it for your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFpz-3_vlJgp"
   },
   "outputs": [],
   "source": [
    "img_final = tf.image.resize_images(img_tensor, [192, 192])\n",
    "img_final = img_final/255.0\n",
    "print(img_final.shape)\n",
    "print(img_final.numpy().min())\n",
    "print(img_final.numpy().max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCsAa4Psl4AQ"
   },
   "source": [
    "Wrap up these up in simple functions for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmUiZJNU73vA"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize_images(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "einETrJnO-em"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "  image = tf.read_file(path)\n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3brWQcdtz78y"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = all_image_paths[0]\n",
    "label = all_image_labels[0]\n",
    "\n",
    "plt.imshow(load_and_preprocess_image(img_path))\n",
    "plt.grid(False)\n",
    "plt.xlabel(caption_image(img_path))\n",
    "plt.title(label_names[label].title())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2TCr1TQ8pA3"
   },
   "source": [
    "## Build a `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6H9Z5Mq63nSH"
   },
   "source": [
    "### A dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GN-s04s-6Luq"
   },
   "source": [
    "The easiest way to build a `tf.data.Dataset` is using the `from_tensor_slices` method.\n",
    "\n",
    "Slicing the array of strings, results in a dataset of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oRPG3Jz3ie_"
   },
   "outputs": [],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uML4JeMmIAvO"
   },
   "source": [
    "The `output_shapes` and `output_types` fields describe the content of each item in the dataset. In this case it is a set of scalar binary-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIsNflFbIK34"
   },
   "outputs": [],
   "source": [
    "print('shape: ', repr(path_ds.output_shapes))\n",
    "print('type: ', path_ds.output_types)\n",
    "print()\n",
    "print(path_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjyGcM8OwBJ2"
   },
   "source": [
    "Now create a new dataset that loads and formats images on the fly by mapping `preprocess_image` over the dataset of paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1iba6f4khu-"
   },
   "outputs": [],
   "source": [
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLUPs2a-lEEJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for n,image in enumerate(image_ds.take(4)):\n",
    "  plt.subplot(2,2,n+1)\n",
    "  plt.imshow(image)\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.xlabel(caption_image(all_image_paths[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6FNqPbxkbdx"
   },
   "source": [
    "### A dataset of `(image, label)` pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgvrWLKG67-x"
   },
   "source": [
    "Using the same `from_tensor_slices` method we can build a dataset of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgBsAiV06udj"
   },
   "outputs": [],
   "source": [
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEsk5nN0vyeX"
   },
   "outputs": [],
   "source": [
    "for label in label_ds.take(10):\n",
    "  print(label_names[label.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHjgrEeTxyYz"
   },
   "source": [
    "Since the datasets are in the same order we can just zip them together to get a dataset of `(image, label)` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOEWNMdQwsbN"
   },
   "outputs": [],
   "source": [
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yA2F09SJLMuM"
   },
   "source": [
    "The new dataset's `shapes` and `types` are tuples of shapes and types as well, describing each field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DuVYNinrLL-N"
   },
   "outputs": [],
   "source": [
    "print('image shape: ', image_label_ds.output_shapes[0])\n",
    "print('label shape: ', image_label_ds.output_shapes[1])\n",
    "print('types: ', image_label_ds.output_types)\n",
    "print()\n",
    "print(image_label_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2WYMikoPWOQX"
   },
   "source": [
    "Note: When you have arrays like `all_image_labels` and `all_image_paths` an alternative to `tf.data.dataset.Dataset.zip` is to slice the pair of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOFwZI-2WhzV"
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "\n",
    "# The tuples are unpacked into the positional arguments of the mapped function \n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), label\n",
    "\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "image_label_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYGCgJuR_9Qp"
   },
   "source": [
    "### Basic methods for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwZavzgsIytz"
   },
   "source": [
    "To train a model with this dataset you will want the data:\n",
    "\n",
    "* To be well shuffled.\n",
    "* To be batched.\n",
    "* To repeat forever.\n",
    "* Batches to be available as soon as possible.\n",
    "\n",
    "These features can be easily added using the `tf.data` api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZmZJx8ePw_5"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JsM-xHiFCuW"
   },
   "source": [
    "There are a few things to note here:\n",
    "\n",
    "1. The order is important. \n",
    "\n",
    "  * A `.shuffle` before a `.repeat` would shuffle items across epoch boundaries (some items will ve seen twice before others are seen at all). \n",
    "  * A `.shuffle` after a `.batch` would shuffle the order of the batches, but not shuffle the items across batches.\n",
    "\n",
    "1. We use a `buffer_size` the same size as the dataset for a full shuffle. Up to the dataset size, large values provide better randomization, but use more memory. \n",
    "\n",
    "1. The shuffle buffer is filled before any elements are pulled from it. So a large `buffer_size` may cause a delay when your `Dataset` is starting.\n",
    "\n",
    "1. The shuffeled dataset doesn't report the end of a dataset until the shuffle-buffer is completely empty. The `Dataset` is restarted by `.repeat`, causing another wait for the shuffle-buffer to be filled.\n",
    "\n",
    "This last point can be addressed by using the `tf.data.Dataset.apply` method with the fused `tf.data.experimental.shuffle_and_repeat` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ocr6PybXNDoO"
   },
   "outputs": [],
   "source": [
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBBZMSuAmQVL"
   },
   "source": [
    "### Pipe the dataset to a model\n",
    "\n",
    "Fetch a copy of MobileNet v2 from `tf.keras.applications`.\n",
    "\n",
    "This will be used for a simple transfer learning example.\n",
    "\n",
    "Set the MobileNet weights to be non-trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbJrXn9omO_g"
   },
   "outputs": [],
   "source": [
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "mobile_net.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7NVWiLF3Vbf"
   },
   "source": [
    "This model expects its input to be normalized to the `[-1,1]` range:\n",
    "\n",
    "```\n",
    "help(keras_applications.mobilenet_v2.preprocess_input)\n",
    "```\n",
    "\n",
    "<pre>\n",
    "...\n",
    "This function applies the \"Inception\" preprocessing which converts\n",
    "the RGB values from [0, 255] to [-1, 1] \n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CboYya6LmdQI"
   },
   "source": [
    "So before the passing it to the MobilNet model, we need to convert the input from a range of `[0,1]` to `[-1,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNOkHUGv3FYq"
   },
   "outputs": [],
   "source": [
    "def change_range(image,label):\n",
    "  return 2*image-1, label\n",
    "\n",
    "keras_ds = ds.map(change_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDzZ3Nye5Rpv"
   },
   "source": [
    "The MobileNet returns a `6x6` spatial grid of features for each image.\n",
    "\n",
    "Pass it a batch of images to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzAhGkEK6WuE"
   },
   "outputs": [],
   "source": [
    "# The dataset may take a few seconds to start, as it fills its shuffle buffer.\n",
    "image_batch, label_batch = next(iter(keras_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcFdiWpO5WbV"
   },
   "outputs": [],
   "source": [
    "feature_map_batch = mobile_net(image_batch)\n",
    "print(feature_map_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrbjEvaC5XmU"
   },
   "source": [
    "So build a model wrapped around MobileNet, and use `tf.keras.layers.GlobalAveragePooling2D` to average over those space dimensions, before the output `tf.keras.layers.Dense` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0ooIU9fNjPJ"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  mobile_net,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(len(label_names))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foQYUJs97V4V"
   },
   "source": [
    "Now it produces outputs of the expected shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nwYxvpj7ZEf"
   },
   "outputs": [],
   "source": [
    "logit_batch = model(image_batch).numpy()\n",
    "\n",
    "print(\"min logit:\", logit_batch.min())\n",
    "print(\"max logit:\", logit_batch.max())\n",
    "print()\n",
    "\n",
    "print(\"Shape:\", logit_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFc4I_J2nNOJ"
   },
   "source": [
    "Compile the model to describe the training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWGqLEWYRNvv"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF1mO6haBOSd"
   },
   "source": [
    "There are 2 trainable variables: the Dense `weights` and `bias`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPQ5yqyKBJMm"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kug5Wg66UJjl"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_glpYZ-nYC_"
   },
   "source": [
    "Train the model.\n",
    "\n",
    "Normally you would specify the real number of steps per epoch, but for demonstration purposes only run 3 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnXPRNWoTypI"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch=tf.ceil(len(all_image_paths)/BATCH_SIZE).numpy()\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_8sabaaSGAp"
   },
   "outputs": [],
   "source": [
    "model.fit(ds, epochs=1, steps_per_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMVnoBcG_NlQ"
   },
   "source": [
    "## Performance\n",
    "\n",
    "Note: This section just shows a couple of easy tricks that may help performance. For an in depth guide see [Input Pipeline Performance](https://www.tensorflow.org/guide/performance/datasets).\n",
    "\n",
    "The simple pipeline used above reads each file individually, on each epoch. This is fine for local training on CPU but may not be sufficient for GPU training, and is totally inappropriate for any sort of distributed training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNmQqgGhLWie"
   },
   "source": [
    "To investigate, first build a simple function to check the performance of our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gFVe1rp_MYr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(ds, batches=2*steps_per_epoch+1):\n",
    "  overall_start = time.time()\n",
    "  # Fetch a single batch to prime the pipeline (fill the shuffle buffer),\n",
    "  # before starting the timer\n",
    "  it = iter(ds.take(batches+1))\n",
    "  next(it)\n",
    "\n",
    "  start = time.time()\n",
    "  for i,(images,labels) in enumerate(it):\n",
    "    if i%10 == 0:\n",
    "      print('.',end='')\n",
    "  print()\n",
    "  end = time.time()\n",
    "\n",
    "  duration = end-start\n",
    "  print(\"{} batches: {} s\".format(batches, duration))\n",
    "  print(\"{:0.5f} Images/s\".format(BATCH_SIZE*batches/duration))\n",
    "  print(\"Total time: {}s\".format(end-overall_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYiOr4vdLcNX"
   },
   "source": [
    "The performance of the current dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDxLwMJOReVe"
   },
   "outputs": [],
   "source": [
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjouTJadRxyp"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsLlXMO7EWBR"
   },
   "source": [
    "### Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lV1NOn2zE2lR"
   },
   "source": [
    "Use `tf.data.Dataset.cache` to easily cache calculations across epochs. This is especially performant if the dataq fits in memory.\n",
    "\n",
    "Here the images are cached, after being pre-precessed (decoded and resized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qj_U09xpDvOg"
   },
   "outputs": [],
   "source": [
    "ds = image_label_ds.cache()\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdxpvQ7VEo3y"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usIv7MqqZQps"
   },
   "source": [
    "One disadvantage to using an in memory cache is that the cache must be rebuilt on each run, giving the same startup delay each time the dataset is started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKX6ergKb_xd"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUzpG4lYNkN-"
   },
   "source": [
    "If the data doesn't fit in memory, use a cache file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIvF8K4GMq0g"
   },
   "outputs": [],
   "source": [
    "ds = image_label_ds.cache(filename='./cache.tf-data')\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTIj6IOmM4yA"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqo3dyB0Z4t2"
   },
   "source": [
    "The cache file also has the advantage that it can be used to quickly restart the dataset without rebuilding the cache. Note how much faster it is the second time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZhVdR8MbaUj"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqOVlf8tFrDU"
   },
   "source": [
    "### TFRecord File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1llOTwWFzmR"
   },
   "source": [
    "#### Raw image data\n",
    "\n",
    "TFRecord files are a simple format to store a sequence of binary blobs. By packing multiple examples into the same file, TensorFlow is able to read multiple examples at once, which is especially important for performance when using a remote storage service such as GCS.\n",
    "\n",
    "First, build a TFRecord file from the raw image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqtARqKuHQLu"
   },
   "outputs": [],
   "source": [
    "image_ds = tf.data.Dataset.from_tensor_slices(all_image_paths).map(tf.read_file)\n",
    "tfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\n",
    "tfrec.write(image_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "flR2GXWFKcO1"
   },
   "source": [
    "Next build a dataset that reads from the TFRecord file and decodes/reformats the images using the `preprocess_image` function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9PVUL2SFufn"
   },
   "outputs": [],
   "source": [
    "image_ds = tf.data.TFRecordDataset('images.tfrec').map(preprocess_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRp1eZDRKzyN"
   },
   "source": [
    "Zip that with the labels dataset we defined earlier, to get the expected `(image,label)` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XI_nDU2KuhS"
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds=ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ReSapoPK22E"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wb7VyoKNOMms"
   },
   "source": [
    "This is slower than the `cache` version because we have not cached the preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NF9W-CTKkM-f"
   },
   "source": [
    "#### Serialized Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J9HzljSPkxt0"
   },
   "source": [
    "To save some preprocessing to the TFRecord file, first make a dataset of the processed images, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzS0Azukkjyw"
   },
   "outputs": [],
   "source": [
    "paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = paths_ds.map(load_and_preprocess_image)\n",
    "image_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onWOwLpYlzJQ"
   },
   "source": [
    "Now instead of a dataset of `.jpeg` strings, this is a dataset of tensors.\n",
    "\n",
    "To serialize this to a TFRecord file you first convert the dataset of tensors to a dataset of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxZSwnRllyf0"
   },
   "outputs": [],
   "source": [
    "ds = image_ds.map(tf.serialize_tensor)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9N6hJWAkKPC"
   },
   "outputs": [],
   "source": [
    "tfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\n",
    "tfrec.write(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlFc9dJSmcx0"
   },
   "source": [
    "With the preprocessing cached, data can be loaded from the TFrecord file quite efficiently. Just remember to de-serialized tensor before trying to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsqFyTBFmSCZ"
   },
   "outputs": [],
   "source": [
    "RESTORE_TYPE = image_ds.output_types\n",
    "RESTORE_SHAPE = image_ds.output_shapes\n",
    "\n",
    "ds = tf.data.TFRecordDataset('images.tfrec')\n",
    "\n",
    "def parse(x):\n",
    "  result = tf.parse_tensor(x, out_type=RESTORE_TYPE)\n",
    "  result = tf.reshape(result, RESTORE_SHAPE)\n",
    "  return result\n",
    "\n",
    "ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPs_sLV9pQg5"
   },
   "source": [
    "Now, add the labels and apply the same standard operations as before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYxBwaLYnGop"
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.zip((ds, label_ds))\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds=ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8X6RmGan1-P"
   },
   "outputs": [],
   "source": [
    "timeit(ds)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "images.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
